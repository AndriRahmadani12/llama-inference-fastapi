# A simple FastAPI application for serving Llama model inference.

## Description
This project provides a REST API interface for running inference using the Llama language model. It's built with FastAPI for high performance and easy deployment.
